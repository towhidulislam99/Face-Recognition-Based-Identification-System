{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <link rel="stylesheet" href="{% static 'css/style.css' %}">
    <title> Face Recognition Based Identification System</title>
</head>
<body>
<div class = "Top-Section">

    <div class="top_bar">
        <div class = "logo">
            <a href=""><img src="{% static 'images/logo-1.png' %}"  alt="" >
            </a>
        <h1>Face Recognition Based Identification System</h1>

    </div>

    </div>
</div>

<div class="body-section">
<div class="geobag-section">
    <h1>Face Recognition Based Identification System</h1>
    <div class="line"></div>
<div class="Details">
<h3>Introduction: </h3>
<p>In an increasingly digitized world, where security and identification play pivotal roles, facial recognition technology emerges as a powerful tool. Facial recognition, a form of biometric security, revolutionizes the way we identify and confirm individuals' identities using their unique facial features. It operates on the principle of analyzing distinct facial characteristics to distinguish one person from another accurately. This technology finds application in various domains, ranging from unlocking smartphones to enhancing security and law enforcement measures.Facial recognition systems are part of a broader category of biometric security solutions, which include voice recognition, fingerprint recognition, and iris or retina recognition. Unlike traditional identification methods such as passwords or PINs, facial recognition offers a seamless and efficient way to verify identities. Its versatility allows it to be deployed in diverse scenarios, from authentication processes to surveillance systems. The Figure (1) illustrates an initial image before facial detection. </p>

<div class="details-img">
    {%for i in geobagriverbankdata%}
    <a href=""><img src="{{ i.geobag_at_riverbank_img.url }}" alt="Your Image Description"></a>
    <p>{{i.image_figure_text}}</p>
    {%endfor%}
</div>

<p>This technology's functionality extends beyond mere identificationâ€”it can also be utilized for surveillance and monitoring purposes. By matching faces captured by cameras with images stored in databases or watch lists, facial recognition aids in tracking individuals of interest in real-time. However, the widespread adoption of facial recognition has sparked debates regarding privacy concerns and ethical implications. And Figure (2) shows the same image after facial detection:  </p>

<div class="details-img-2">
    {%for i in filledriverbankdata%}
    <a href=""><img src="{{ i.geobag_counting_riverbank_img.url }}" alt="Your Image Description"></a>
    <p>{{i.counting_figure_text}}</p>
    {%endfor%}
</div>

<p>Despite the controversies surrounding its usage, facial recognition technology continues to evolve, offering advancements in accuracy, efficiency, and reliability. As its applications diversify and its capabilities expand, understanding the underlying mechanisms and implications of facial recognition becomes increasingly crucial in navigating the intersection of technology and society. </p>


 <h3>2. Working Procedures:</h3>

<p> <strong>Capturing: </strong>The camera device(s) which is/are to used to take images, so that the model can detect faces in the image (if there any). These cameras are installed where we want capture the images of the passer by. For live monitoring, these cameras provide live video feed to the model and the model then detects any faces in the image.</p>

<p> <strong>Extracting: </strong>In the extracting part, the live video feeds from the camera devices are used detect faces in each frame. Each frame is passed through the model, the model detects faces if there any, and generates feature embedding/vectors and other information for each detected faces. These are then used in comparing and matching.</p>

<p> <strong>Comparing: </strong>After detection of faces in each frame by the model, the software then compare the generated or extracted features from the detected faces with the database containing the feature embedding/vectors for each known person.</p>

<p> <strong>Matching: </strong>We measure the cosine similarity between the embeddings while comparing. If the similarity score is above a certain threshold, then we've found a match and the person is verified.</p>

<div class="proprosed-img-2">
    {%for i in testingproceduresdata%}
    <a href=""><img src="{{ i.testing_procedures_img.url }}" alt="Your Image Description"></a>
    <p>{{i.testing_procedures_figure_text}}</p>
    {%endfor%}
</div> 

     <!-- <div class="details-img-3">
        {%for i in prototypeproposeddata%}
        <a href=""><img src="{{ i.prototype_of_proposed_img.url }}" alt="Your Image Description"></a>
        <p>{{i.proposed_figure_text}}</p>
        {%endfor%}
    </div> -->

</div>


<div class="Proposed-Methodology">
    {% comment %} <h1>Proposed TSGCS Methodology: </h1> {% endcomment %}
    <h3 style ="align-items: center; font-size:  25px; text-align: center;">System Overview </h3>
    <div class="line-1"></div>
    {% comment %} <p>Before applying YOLOv3 in our proposed system, it is mandatory to collect image dataset of geobags properly because it will assist us to achieve better accuracy. After Collecting the dataset, we prepare our dataset as follows:</p> {% endcomment %}

    <div class="proprosed-img-1">
        {%for i in preparingdatasetdata%}
        <a href=""><img src="{{ i.preparing_pataset_img.url }}" alt="Your Image Description"></a>
        <p>{{i.preparing_dataset_figure_text}}</p>
        {%endfor%}
    </div>

    {% comment %} <h3>2. Training and Testing Procedures:</h3>

    <p>In our proposed system, we utilize YOLO (You Look Only Once) based Deep Learning architecture to detect the multi-geobag from image or video. There are different versions (v1, v2, v3, v4, v5) available of YOLO. In this case, we used YOLOv3 in our proposed system. YOLOv3 has a very high accuracy while also being able to run in real-time or used for real-time applications. The algorithm uses only one forward propagation pass through the network to make the predictions. YOLOv3 uses a new backbone network Darknet-53 that utilizes residual connections as well as some improvements to the bounding box prediction step, and use of three different scales from which to extract features. The Figure (6) describe the training and testing procedures of the proposed YOLV3 based TSGCS. </p>

    <div class="proprosed-img-2">
        {%for i in testingproceduresdata%}
        <a href=""><img src="{{ i.testing_procedures_img.url }}" alt="Your Image Description"></a>
        <p>{{i.testing_procedures_figure_text}}</p>
        {%endfor%}
    </div> {% endcomment %}


</div>


{% comment %} <div class="toonificationSection">
    <div class="header-section">
        {% for i in toonificationheadingdata %}
        <h1>{{i.toonification_heading}}</h1>
        {%endfor%}
    </div>
    <div class="image-section1">
        {% for i in toonificationimagedata %}
            <img src="{{ i.toonification_photo.url }}" alt="Your Image Description">
        {%endfor%}
        
    </div>
    <div class="line1"></div>
    <div class="line1"></div>
</div> {% endcomment %}


<div class="toonificationSection">
    <div class="header-section">
        {% for i in toonificationheadingdata %}
        <h1>{{i.toonification_heading}}</h1>
        {%endfor%}
    </div>
    <div class="recognision_video_Section">
        {% for i in facerecognitionvideodata %}
        <video width="480" height="360" controls>
            <source src="/media/{{ i.recognition_video }}" alt="No Videos" type="video/mp4">
            Your browser does not support the video tag.
        </video>
        {%endfor%}
        
    </div>
    <div class="line1"></div>
    <div class="line1"></div>
</div>




</div>
</div>




</body>
</html>